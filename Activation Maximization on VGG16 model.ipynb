{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 9s 0us/step\n",
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compute filters 0 to 512\n",
      "Costs of filter   0:   404 ( 112.66s )\n",
      "Costs of filter   2:   421 ( 116.53s )\n",
      "Costs of filter   3:   515 ( 121.55s )\n",
      "Costs of filter   4:   606 ( 117.57s )\n",
      "Costs of filter   5:   494 ( 124.25s )\n",
      "Costs of filter   7:   975 ( 121.37s )\n",
      "Costs of filter   8:   878 ( 123.72s )\n",
      "Costs of filter   9:   462 ( 118.29s )\n",
      "Costs of filter  10:   540 ( 121.75s )\n",
      "Costs of filter  11:   765 ( 120.79s )\n",
      "Costs of filter  13:   355 ( 119.04s )\n",
      "Costs of filter  14:   681 ( 120.35s )\n",
      "Costs of filter  15:   518 ( 133.17s )\n",
      "Costs of filter  17:   831 ( 123.12s )\n",
      "Costs of filter  20:   532 ( 128.98s )\n",
      "Costs of filter  24:   461 ( 118.23s )\n",
      "Costs of filter  25:   576 ( 129.57s )\n",
      "Costs of filter  27:   884 ( 120.80s )\n",
      "Costs of filter  28:   527 ( 124.12s )\n",
      "Costs of filter  29:   554 ( 122.84s )\n",
      "Costs of filter  30:   573 ( 121.49s )\n",
      "Costs of filter  31:   404 ( 121.75s )\n",
      "Costs of filter  32:   381 ( 120.23s )\n",
      "Costs of filter  33:   923 ( 124.17s )\n",
      "Costs of filter  34:   495 ( 125.05s )\n",
      "Costs of filter  36:   861 ( 120.99s )\n",
      "Costs of filter  37:   784 ( 119.46s )\n",
      "Costs of filter  40:   858 ( 119.04s )\n",
      "Costs of filter  42:   854 ( 118.59s )\n",
      "Costs of filter  43:   420 ( 120.56s )\n",
      "Costs of filter  44:   603 ( 118.31s )\n",
      "Costs of filter  46:   958 ( 116.57s )\n",
      "Costs of filter  47:   689 ( 118.20s )\n",
      "Costs of filter  48:   697 ( 117.95s )\n",
      "Costs of filter  49:   817 ( 120.45s )\n",
      "Costs of filter  51:   462 ( 117.05s )\n",
      "Costs of filter  53:   671 ( 118.94s )\n",
      "Costs of filter  55:   409 ( 119.21s )\n",
      "Costs of filter  58:   347 ( 119.89s )\n",
      "Costs of filter  59:   890 ( 123.98s )\n",
      "Costs of filter  60:   759 ( 134.46s )\n",
      "Costs of filter  61:   916 ( 164.55s )\n",
      "Costs of filter  62:   624 ( 137.00s )\n",
      "Costs of filter  63:  1077 ( 130.00s )\n",
      "Costs of filter  64:  1195 ( 133.56s )\n",
      "Costs of filter  65:   228 ( 121.88s )\n",
      "Costs of filter  70:   579 ( 138.20s )\n",
      "Costs of filter  73:   699 ( 125.08s )\n",
      "Costs of filter  74:   486 ( 126.13s )\n",
      "Costs of filter  75:   318 ( 131.24s )\n",
      "Costs of filter  76:   852 ( 120.51s )\n",
      "Costs of filter  79:   777 ( 118.69s )\n",
      "Costs of filter  80:   445 ( 120.15s )\n",
      "Costs of filter  81:   469 ( 120.55s )\n",
      "Costs of filter  82:   681 ( 120.37s )\n",
      "Costs of filter  84:   531 ( 122.88s )\n",
      "Costs of filter  86:  1041 ( 123.01s )\n",
      "Costs of filter  87:   769 ( 124.63s )\n",
      "Costs of filter  88:   908 ( 124.90s )\n",
      "Costs of filter  91:   639 ( 124.75s )\n",
      "Costs of filter  92:   457 ( 122.25s )\n",
      "Costs of filter  93:   579 ( 123.20s )\n",
      "Costs of filter  97:   436 ( 124.59s )\n",
      "Costs of filter  99:   445 ( 137.49s )\n",
      "Costs of filter 101:   337 ( 125.27s )\n",
      "Costs of filter 102:   883 ( 126.15s )\n",
      "Costs of filter 103:   974 ( 126.47s )\n",
      "Costs of filter 110:   630 ( 123.21s )\n",
      "Costs of filter 112:   288 ( 128.58s )\n",
      "Costs of filter 113:   605 ( 125.29s )\n",
      "Costs of filter 114:   732 ( 132.32s )\n",
      "Costs of filter 115:   420 ( 127.43s )\n",
      "Costs of filter 119:   820 ( 126.86s )\n",
      "Costs of filter 121:   431 ( 130.29s )\n",
      "Costs of filter 124:   357 ( 131.15s )\n",
      "Costs of filter 126:   962 ( 127.33s )\n",
      "Costs of filter 127:   426 ( 137.00s )\n",
      "Costs of filter 128:   833 ( 130.84s )\n",
      "Costs of filter 131:   567 ( 128.80s )\n",
      "Costs of filter 132:   362 ( 127.64s )\n",
      "Costs of filter 133:   519 ( 128.28s )\n",
      "Costs of filter 135:   410 ( 125.05s )\n",
      "Costs of filter 136:   716 ( 129.12s )\n",
      "Costs of filter 137:   420 ( 133.50s )\n",
      "Costs of filter 138:  1383 ( 131.54s )\n",
      "Costs of filter 139:   395 ( 127.09s )\n",
      "Costs of filter 140:   529 ( 127.36s )\n",
      "Costs of filter 141:   592 ( 128.74s )\n",
      "Costs of filter 143:   840 ( 132.64s )\n",
      "Costs of filter 145:   487 ( 135.10s )\n",
      "Costs of filter 146:  1245 ( 126.01s )\n",
      "Costs of filter 149:   544 ( 128.88s )\n",
      "Costs of filter 151:   582 ( 130.06s )\n",
      "Costs of filter 152:   604 ( 131.99s )\n",
      "Costs of filter 154:   651 ( 127.58s )\n",
      "Costs of filter 157:   875 ( 127.23s )\n",
      "Costs of filter 158:   709 ( 129.03s )\n",
      "Costs of filter 161:   445 ( 128.24s )\n",
      "Costs of filter 162:   643 ( 129.97s )\n",
      "Costs of filter 163:   706 ( 127.44s )\n",
      "Costs of filter 165:   496 ( 135.85s )\n",
      "Costs of filter 166:   713 ( 135.09s )\n",
      "Costs of filter 167:   696 ( 132.83s )\n",
      "Costs of filter 168:   523 ( 129.13s )\n",
      "Costs of filter 170:   742 ( 129.14s )\n",
      "Costs of filter 171:   638 ( 128.28s )\n",
      "Costs of filter 173:   956 ( 127.32s )\n",
      "Costs of filter 174:   625 ( 122.83s )\n",
      "Costs of filter 175:   479 ( 124.54s )\n",
      "Costs of filter 177:   788 ( 123.96s )\n",
      "Costs of filter 180:   425 ( 124.10s )\n",
      "Costs of filter 181:   609 ( 123.42s )\n",
      "Costs of filter 182:  1128 ( 124.80s )\n",
      "Costs of filter 183:   474 ( 121.73s )\n",
      "Costs of filter 185:   625 ( 123.73s )\n",
      "Costs of filter 186:   531 ( 125.13s )\n",
      "Costs of filter 187:   991 ( 123.96s )\n",
      "Costs of filter 188:   544 ( 123.78s )\n",
      "Costs of filter 190:   441 ( 121.88s )\n",
      "Costs of filter 201:   418 ( 123.28s )\n",
      "Costs of filter 202:   529 ( 124.16s )\n",
      "Costs of filter 203:   541 ( 123.33s )\n",
      "Costs of filter 204:   428 ( 123.04s )\n",
      "Costs of filter 206:   505 ( 121.74s )\n",
      "Costs of filter 207:   356 ( 122.94s )\n",
      "Costs of filter 208:   978 ( 121.71s )\n",
      "Costs of filter 209:   724 ( 123.25s )\n",
      "Costs of filter 211:   390 ( 120.91s )\n",
      "Costs of filter 212:   359 ( 126.45s )\n",
      "Costs of filter 213:   806 ( 157.51s )\n",
      "Costs of filter 214:   542 ( 142.19s )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 218:   454 ( 150.12s )\n",
      "Costs of filter 219:   840 ( 154.80s )\n",
      "Costs of filter 220:   785 ( 144.60s )\n",
      "Costs of filter 221:   603 ( 144.87s )\n",
      "Costs of filter 223:   395 ( 160.51s )\n",
      "Costs of filter 225:   176 ( 156.39s )\n",
      "Costs of filter 227:   449 ( 153.93s )\n",
      "Costs of filter 229:  1013 ( 156.59s )\n",
      "Costs of filter 233:   384 ( 153.38s )\n",
      "Costs of filter 235:   785 ( 156.71s )\n",
      "Costs of filter 236:   564 ( 153.69s )\n",
      "Costs of filter 237:   530 ( 145.68s )\n",
      "Costs of filter 238:   600 ( 138.95s )\n",
      "Costs of filter 240:   552 ( 143.31s )\n",
      "Costs of filter 241:   712 ( 143.17s )\n",
      "Costs of filter 243:   774 ( 135.33s )\n",
      "Costs of filter 245:  1020 ( 137.71s )\n",
      "Costs of filter 246:   344 ( 138.60s )\n",
      "Costs of filter 247:   513 ( 136.78s )\n",
      "Costs of filter 249:   601 ( 144.00s )\n",
      "Costs of filter 251:   476 ( 151.17s )\n",
      "Costs of filter 255:   646 ( 139.23s )\n",
      "Costs of filter 256:   435 ( 132.06s )\n",
      "Costs of filter 257:   551 ( 152.70s )\n",
      "Costs of filter 258:   609 ( 150.84s )\n",
      "Costs of filter 259:   451 ( 152.08s )\n",
      "Costs of filter 262:   479 ( 149.64s )\n",
      "Costs of filter 263:   552 ( 143.52s )\n",
      "Costs of filter 264:   584 ( 139.04s )\n",
      "Costs of filter 265:   844 ( 139.05s )\n",
      "Costs of filter 267:   389 ( 140.88s )\n",
      "Costs of filter 268:   482 ( 138.29s )\n",
      "Costs of filter 269:   620 ( 140.75s )\n",
      "Costs of filter 270:  1359 ( 146.60s )\n",
      "Costs of filter 271:   596 ( 146.99s )\n",
      "Costs of filter 272:   636 ( 146.29s )\n",
      "Costs of filter 275:   542 ( 148.43s )\n",
      "Costs of filter 278:   613 ( 148.42s )\n",
      "Costs of filter 279:   650 ( 128.39s )\n",
      "Costs of filter 280:   255 ( 120.93s )\n",
      "Costs of filter 281:   582 ( 134.43s )\n",
      "Costs of filter 282:   475 ( 149.69s )\n",
      "Costs of filter 285:   622 ( 147.73s )\n",
      "Costs of filter 286:  1005 ( 138.77s )\n",
      "Costs of filter 287:   465 ( 143.52s )\n",
      "Costs of filter 289:   475 ( 137.95s )\n",
      "Costs of filter 293:   495 ( 142.90s )\n",
      "Costs of filter 294:   699 ( 141.20s )\n",
      "Costs of filter 295:   836 ( 136.92s )\n",
      "Costs of filter 296:   432 ( 173.76s )\n",
      "Costs of filter 297:   668 ( 237.05s )\n",
      "Costs of filter 300:  1057 ( 269.62s )\n",
      "Costs of filter 301:   886 ( 178.05s )\n",
      "Costs of filter 302:   922 ( 138.31s )\n",
      "Costs of filter 303:   533 ( 168.46s )\n",
      "Costs of filter 305:   461 ( 162.58s )\n",
      "Costs of filter 306:   693 ( 151.00s )\n",
      "Costs of filter 308:   733 ( 149.24s )\n",
      "Costs of filter 309:  1303 ( 143.59s )\n",
      "Costs of filter 311:   440 ( 152.43s )\n",
      "Costs of filter 318:   465 ( 152.03s )\n",
      "Costs of filter 320:   622 ( 151.69s )\n",
      "Costs of filter 322:   739 ( 157.34s )\n",
      "Costs of filter 323:   569 ( 144.98s )\n",
      "Costs of filter 328:   705 ( 149.55s )\n",
      "Costs of filter 331:   536 ( 150.61s )\n",
      "Costs of filter 333:   413 ( 148.51s )\n",
      "Costs of filter 334:   785 ( 125.08s )\n",
      "Costs of filter 335:   648 ( 129.31s )\n",
      "Costs of filter 336:   532 ( 131.24s )\n",
      "Costs of filter 339:   603 ( 135.35s )\n",
      "Costs of filter 341:   406 ( 124.73s )\n",
      "Costs of filter 343:   316 ( 126.30s )\n",
      "Costs of filter 345:   441 ( 139.90s )\n",
      "Costs of filter 346:   931 ( 136.49s )\n",
      "Costs of filter 348:   738 ( 146.54s )\n",
      "Costs of filter 349:   496 ( 157.40s )\n",
      "Costs of filter 352:   598 ( 150.17s )\n",
      "Costs of filter 353:   671 ( 127.09s )\n",
      "Costs of filter 356:   829 ( 155.40s )\n",
      "Costs of filter 357:   477 ( 147.84s )\n",
      "Costs of filter 359:   606 ( 152.97s )\n",
      "Costs of filter 360:   364 ( 145.39s )\n",
      "Costs of filter 361:   522 ( 145.42s )\n",
      "Costs of filter 362:   630 ( 147.48s )\n",
      "Costs of filter 365:   769 ( 151.68s )\n",
      "Costs of filter 366:   370 ( 150.12s )\n",
      "Costs of filter 367:   742 ( 150.98s )\n",
      "Costs of filter 368:   918 ( 149.30s )\n",
      "Costs of filter 371:  1161 ( 136.66s )\n",
      "Costs of filter 374:   561 ( 133.47s )\n",
      "Costs of filter 375:   554 ( 139.54s )\n",
      "Costs of filter 376:   968 ( 146.58s )\n",
      "Costs of filter 377:   691 ( 147.09s )\n",
      "Costs of filter 378:   583 ( 142.34s )\n",
      "Costs of filter 380:   518 ( 138.32s )\n",
      "Costs of filter 383:   982 ( 143.52s )\n",
      "Costs of filter 389:   484 ( 141.68s )\n",
      "Costs of filter 393:   450 ( 141.51s )\n",
      "Costs of filter 394:   610 ( 146.02s )\n",
      "Costs of filter 397:   559 ( 142.64s )\n",
      "Costs of filter 399:   789 ( 139.64s )\n",
      "Costs of filter 402:   385 ( 137.61s )\n",
      "Costs of filter 405:   684 ( 114.95s )\n",
      "Costs of filter 410:   285 ( 113.40s )\n",
      "Costs of filter 412:   826 ( 114.58s )\n",
      "Costs of filter 414:   410 ( 114.36s )\n",
      "Costs of filter 415:   931 ( 116.70s )\n",
      "Costs of filter 417:   670 ( 114.91s )\n",
      "Costs of filter 418:   666 ( 112.83s )\n",
      "Costs of filter 421:   517 ( 116.80s )\n",
      "Costs of filter 422:   480 ( 115.49s )\n",
      "Costs of filter 423:   773 ( 119.65s )\n",
      "Costs of filter 424:   593 ( 115.56s )\n",
      "Costs of filter 426:   504 ( 115.04s )\n",
      "Costs of filter 427:   584 ( 115.10s )\n",
      "Costs of filter 428:   722 ( 115.07s )\n",
      "Costs of filter 430:   457 ( 114.35s )\n",
      "Costs of filter 433:   636 ( 114.76s )\n",
      "Costs of filter 435:   555 ( 113.41s )\n",
      "Costs of filter 436:   824 ( 114.53s )\n",
      "Costs of filter 437:   752 ( 115.65s )\n",
      "Costs of filter 438:   668 ( 112.40s )\n",
      "Costs of filter 439:   817 ( 116.85s )\n",
      "Costs of filter 442:   713 ( 115.01s )\n",
      "Costs of filter 443:   519 ( 115.32s )\n",
      "Costs of filter 444:   676 ( 113.04s )\n",
      "Costs of filter 445:   419 ( 115.08s )\n",
      "Costs of filter 446:   796 ( 112.57s )\n",
      "Costs of filter 449:   539 ( 114.22s )\n",
      "Costs of filter 452:   697 ( 113.69s )\n",
      "Costs of filter 453:   624 ( 112.19s )\n",
      "Costs of filter 457:   621 ( 114.13s )\n",
      "Costs of filter 458:   714 ( 114.67s )\n",
      "Costs of filter 460:   723 ( 114.13s )\n",
      "Costs of filter 461:   421 ( 115.30s )\n",
      "Costs of filter 462:   479 ( 114.61s )\n",
      "Costs of filter 463:   210 ( 112.91s )\n",
      "Costs of filter 464:   441 ( 115.31s )\n",
      "Costs of filter 465:   480 ( 113.57s )\n",
      "Costs of filter 467:   459 ( 112.01s )\n",
      "Costs of filter 473:   730 ( 115.66s )\n",
      "Costs of filter 474:   433 ( 118.44s )\n",
      "Costs of filter 475:   443 ( 118.04s )\n",
      "Costs of filter 476:   520 ( 115.05s )\n",
      "Costs of filter 478:   428 ( 112.52s )\n",
      "Costs of filter 481:   601 ( 112.96s )\n",
      "Costs of filter 482:   300 ( 114.59s )\n",
      "Costs of filter 483:   497 ( 113.64s )\n",
      "Costs of filter 484:   326 ( 113.99s )\n",
      "Costs of filter 485:   976 ( 113.38s )\n",
      "Costs of filter 487:   604 ( 114.75s )\n",
      "Costs of filter 489:   640 ( 112.17s )\n",
      "Costs of filter 490:   636 ( 113.88s )\n",
      "Costs of filter 493:   592 ( 112.91s )\n",
      "Costs of filter 494:   828 ( 115.15s )\n",
      "Costs of filter 495:   629 ( 114.06s )\n",
      "Costs of filter 496:   473 ( 114.82s )\n",
      "Costs of filter 499:   651 ( 113.44s )\n",
      "Costs of filter 500:   768 ( 115.37s )\n",
      "Costs of filter 501:   620 ( 112.08s )\n",
      "Costs of filter 502:   483 ( 113.20s )\n",
      "Costs of filter 503:   471 ( 116.06s )\n",
      "Costs of filter 505:   843 ( 113.31s )\n",
      "Costs of filter 506:   472 ( 116.76s )\n",
      "Costs of filter 509:   463 ( 112.65s )\n",
      "Costs of filter 510:   569 ( 114.62s )\n",
      "Costs of filter 511:   903 ( 113.78s )\n",
      "299 filter processed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image as pil_image\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras import layers\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"utility function to normalize a tensor.\n",
    "    # Arguments\n",
    "        x: An input tensor.\n",
    "    # Returns\n",
    "        The normalized input tensor.\n",
    "    \"\"\"\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"utility function to convert a float array into a valid uint8 image.\n",
    "    # Arguments\n",
    "        x: A numpy-array representing the generated image.\n",
    "    # Returns\n",
    "        A processed numpy-array, which could be used in e.g. imshow.\n",
    "    \"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_image(x, former):\n",
    "    \"\"\"utility function to convert a valid uint8 image back into a float array.\n",
    "       Reverses `deprocess_image`.\n",
    "    # Arguments\n",
    "        x: A numpy-array, which could be used in e.g. imshow.\n",
    "        former: The former numpy-array.\n",
    "                Need to determine the former mean and variance.\n",
    "    # Returns\n",
    "        A processed numpy-array representing the generated image.\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((2, 0, 1))\n",
    "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()\n",
    "\n",
    "\n",
    "def visualize_layer(model,\n",
    "                    layer_name,\n",
    "                    step=1.,\n",
    "                    epochs=15,\n",
    "                    upscaling_steps=9,\n",
    "                    upscaling_factor=1.2,\n",
    "                    output_dim=(412, 412),\n",
    "                    filter_range=(0, None)):\n",
    "    \"\"\"Visualizes the most relevant filters of one conv-layer in a certain model.\n",
    "    # Arguments\n",
    "        model: The model containing layer_name.\n",
    "        layer_name: The name of the layer to be visualized.\n",
    "                    Has to be a part of model.\n",
    "        step: step size for gradient ascent.\n",
    "        epochs: Number of iterations for gradient ascent.\n",
    "        upscaling_steps: Number of upscaling steps.\n",
    "                         Starting image is in this case (80, 80).\n",
    "        upscaling_factor: Factor to which to slowly upgrade\n",
    "                          the image towards output_dim.\n",
    "        output_dim: [img_width, img_height] The output image dimensions.\n",
    "        filter_range: Tupel[lower, upper]\n",
    "                      Determines the to be computed filter numbers.\n",
    "                      If the second value is `None`,\n",
    "                      the last filter will be inferred as the upper boundary.\n",
    "    \"\"\"\n",
    "\n",
    "    def _generate_filter_image(input_img,\n",
    "                               layer_output,\n",
    "                               filter_index):\n",
    "        \"\"\"Generates image for one particular filter.\n",
    "        # Arguments\n",
    "            input_img: The input-image Tensor.\n",
    "            layer_output: The output-image Tensor.\n",
    "            filter_index: The to be processed filter number.\n",
    "                          Assumed to be valid.\n",
    "        #Returns\n",
    "            Either None if no image could be generated.\n",
    "            or a tuple of the image (array) itself and the last loss.\n",
    "        \"\"\"\n",
    "        s_time = time.time()\n",
    "\n",
    "        # we build a loss function that maximizes the activation\n",
    "        # of the nth filter of the layer considered\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "        else:\n",
    "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # we compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "        # normalization trick: we normalize the gradient\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        # we start from a gray image with some random noise\n",
    "        intermediate_dim = tuple(\n",
    "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random(\n",
    "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
    "        else:\n",
    "            input_img_data = np.random.random(\n",
    "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # Slowly upscaling towards the original size prevents\n",
    "        # a dominating high-frequency of the to visualized structure\n",
    "        # as it would occur if we directly compute the 412d-image.\n",
    "        # Behaves as a better starting point for each following dimension\n",
    "        # and therefore avoids poor local minima\n",
    "        for up in reversed(range(upscaling_steps)):\n",
    "            # we run gradient ascent for e.g. 20 steps\n",
    "            for _ in range(epochs):\n",
    "                loss_value, grads_value = iterate([input_img_data])\n",
    "                input_img_data += grads_value * step\n",
    "\n",
    "                # some filters get stuck to 0, we can skip them\n",
    "                if loss_value <= K.epsilon():\n",
    "                    return None\n",
    "\n",
    "            # Calulate upscaled dimension\n",
    "            intermediate_dim = tuple(\n",
    "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
    "            # Upscale\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
    "                                                           pil_image.BICUBIC))\n",
    "            input_img_data = [process_image(img, input_img_data[0])]\n",
    "\n",
    "        # decode the resulting input image\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        e_time = time.time()\n",
    "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
    "                                                                  loss_value,\n",
    "                                                                  e_time - s_time))\n",
    "        return img, loss_value\n",
    "\n",
    "    def _draw_filters(filters, n=None):\n",
    "        \"\"\"Draw the best filters in a nxn grid.\n",
    "        # Arguments\n",
    "            filters: A List of generated images and their corresponding losses\n",
    "                     for each processed filter.\n",
    "            n: dimension of the grid.\n",
    "               If none, the largest possible square will be used\n",
    "        \"\"\"\n",
    "        if n is None:\n",
    "            n = int(np.floor(np.sqrt(len(filters))))\n",
    "\n",
    "        # the filters that have the highest loss are assumed to be better-looking.\n",
    "        # we will only keep the top n*n filters.\n",
    "        filters.sort(key=lambda x: x[1], reverse=True)\n",
    "        filters = filters[:n * n]\n",
    "\n",
    "        # build a black picture with enough space for\n",
    "        # e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between\n",
    "        MARGIN = 5\n",
    "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
    "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
    "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
    "\n",
    "        # fill the picture with our saved filters\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img, _ = filters[i * n + j]\n",
    "                width_margin = (output_dim[0] + MARGIN) * i\n",
    "                height_margin = (output_dim[1] + MARGIN) * j\n",
    "                stitched_filters[\n",
    "                    width_margin: width_margin + output_dim[0],\n",
    "                    height_margin: height_margin + output_dim[1], :] = img\n",
    "\n",
    "        # save the result to disk\n",
    "        save_img('vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
    "\n",
    "    # this is the placeholder for the input images\n",
    "    assert len(model.inputs) == 1\n",
    "    input_img = model.inputs[0]\n",
    "\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "    output_layer = layer_dict[layer_name]\n",
    "    assert isinstance(output_layer, layers.Conv2D)\n",
    "\n",
    "    # Compute to be processed filter range\n",
    "    filter_lower = filter_range[0]\n",
    "    filter_upper = (filter_range[1]\n",
    "                    if filter_range[1] is not None\n",
    "                    else len(output_layer.get_weights()[1]))\n",
    "    assert(filter_lower >= 0\n",
    "           and filter_upper <= len(output_layer.get_weights()[1])\n",
    "           and filter_upper > filter_lower)\n",
    "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
    "\n",
    "    # iterate through each filter and generate its corresponding image\n",
    "    processed_filters = []\n",
    "    for f in range(filter_lower, filter_upper):\n",
    "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
    "\n",
    "        if img_loss is not None:\n",
    "            processed_filters.append(img_loss)\n",
    "\n",
    "    print('{} filter processed.'.format(len(processed_filters)))\n",
    "    # Finally draw and store the best filters to disk\n",
    "    _draw_filters(processed_filters)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # the name of the layer we want to visualize\n",
    "    # (see model definition at keras/applications/vgg16.py)\n",
    "    LAYER_NAME = 'block5_conv1'\n",
    "\n",
    "    # build the VGG16 network with ImageNet weights\n",
    "    vgg = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "    print('Model loaded.')\n",
    "    vgg.summary()\n",
    "\n",
    "    # example function call\n",
    "    visualize_layer(vgg, LAYER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
